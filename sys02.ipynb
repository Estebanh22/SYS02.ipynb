{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Estebanh22/SYS02.ipynb/blob/SYS/sys02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "825ab936",
      "metadata": {
        "id": "825ab936"
      },
      "source": [
        "## Clase 02 - Operaciones entre señales\n",
        "\n",
        "Entre señales es posible realizar diversas operaciones, que permiten obtener información, obtener nuevas señales o transformarlas. Recordemos que para una señal continua o discreta, se podía hacer [escalamiento y desplazamiento en el tiempo  cambio](https://colab.research.google.com/drive/1ILNOKvafhqQX7DuyjIyomHG3zL9cThcJ). Adicionalmente, es posible realizar operaciones de:\n",
        "\n",
        "- Cambio en amplitud y frecuencia.\n",
        "- Suma y resta.\n",
        "- Multiplicación y división.\n",
        "- Modulación de amplitud.\n",
        "- Modulación de frecuencia.\n",
        "- Filtrado.\n",
        "- Aplicacion de transformadas (Fourier) entre otras técnicas.\n",
        "- Detección y eliminación de ruido.\n",
        "- Generación de nuevas señales."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "895906de",
      "metadata": {
        "id": "895906de"
      },
      "source": [
        "## Librerías de procesamiento de audio\n",
        "\n",
        "Para poder verificar algunas de las operaciones mencionadas utilizaremos señales de audio. El procesamiento de señales de audio en Python puede realizarse mediante 3 librerías principales: SciPy, PyDub y Librosa. Las 3 son herramientas útiles para trabajar con archivos de audio en Python, sin embargo su enfoque es diferente.\n",
        "\n",
        "### SciPy (https://scipy.org/)\n",
        "\n",
        "Esta biblioteca ofrece herramientas más amplias de procesamiento de señales, no solo para audio, sino para imágenes, analítica de datos, entre otras tareas. En cuanto a procesamiento de audio, permite realizar transformadas, filtrado, entre otras.\n",
        "\n",
        "### PyDub (https://pypi.org/project/pydub/#description)\n",
        "\n",
        "Su enfoque es la manipulación de archivos de audio. Se pueden desarrollar tareas de edición, conversión y mezclado de pistas, así como para desarrollar operaciones sencillas de procesamiento de audio.\n",
        "\n",
        "### Librosa (https://librosa.org/doc/latest/index.html)\n",
        "\n",
        "Es un paquete para uso con música y análisis de audio. Permite analizar y procesar señales de audio, proporcionando diversas herramientas para actividades de extracción de características, transformación de audio y visualización. *(En el momento esta librería no es compatible con Python 3.11)*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1af17ca2",
      "metadata": {
        "id": "1af17ca2"
      },
      "outputs": [],
      "source": [
        "# CLASE 02 - OPERACIONES ENTRE SEÑALES\n",
        "# Cargar las librerías requeridas para procesar el audio usando SciPy\n",
        "\n",
        "# SciPy para analizar el archivo de audio\n",
        "import scipy.io.wavfile as wav\n",
        "\n",
        "# NumPy para operar sobre el arreglo de datos\n",
        "import numpy as np\n",
        "\n",
        "# MatPlotLib para visualizar el gráfico\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams[\"figure.figsize\"] = [10, 5]\n",
        "\n",
        "# IPython.display para reproducir audio directamente en el notebook\n",
        "from IPython.display import Audio"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e137c2b",
      "metadata": {
        "id": "0e137c2b"
      },
      "source": [
        "## Visualización de una señal de audio con SciPy\n",
        "\n",
        "En el siguiente ejemplo se hace la carga de un archivo wav para ser visualizado en matplotlib. La función wav.read() toma un archivo .wav (ubicado en la carpeta del proyecto), retornando la frecuencia de muestreo (samplerate) y los datos (data).\n",
        "\n",
        "La longitud de la señal se toma a partir de la propiedad *shape* del arreglo de datos (para la primera fila 0). La cantidad de datos, dividido entre la frecuencia de muestreo retornará la longitud (en tiempo) de la forma de onda a visualizar.\n",
        "\n",
        "La función linspace de NumPy toma el invervalo desde un valor inicial (0.) hasta un valor final (length - tiempo total de la señal) y lo divide de forma equitativa para la cantidad de datos a visualizar (data.shape\\[0\\]).\n",
        "\n",
        "Es importante tener en cuenta que esta señal ya ha pasado por los procesos de muestreado y cuantización vistos en la clase anterior (por lo tanto se trabaja como un arreglo de datos en el tiempo)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b30069e",
      "metadata": {
        "scrolled": true,
        "id": "9b30069e",
        "outputId": "b45c4854-0bab-4100-d43c-c70ff57dbc0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-07905317382f>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Reproducir los audios a cargar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mAudio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"files/261870__technicalgeezer__static.wav\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/lib/display.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, filename, url, embed, rate, autoplay, normalize, element_id)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mrate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"rate must be specified when data is a numpy array or list of audio samples.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAudio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_wav\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: rate must be specified when data is a numpy array or list of audio samples."
          ]
        }
      ],
      "source": [
        "# Reproducir los audios a cargar\n",
        "Audio(\"files/261870__technicalgeezer__static.wav\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a337511e",
      "metadata": {
        "scrolled": true,
        "id": "a337511e"
      },
      "outputs": [],
      "source": [
        "# Cargar el primer archivo de audio\n",
        "samplerate1, data1 = wav.read(\"files/261870__technicalgeezer__static.wav\")\n",
        "print(samplerate1, \"Hz\") # Imprimir la frecuencia de muestreo de la primera señal\n",
        "print(data1)\n",
        "\n",
        "# Calcula la longitud (en tiempo) de la señal\n",
        "length1 = data1.shape[0] / samplerate1\n",
        "\n",
        "#La variable independiente time1 se tomará en el rango [0, length1] y se graficará según el número de muestras en el audio1.\n",
        "time1 = np.linspace(0., length1, data1.shape[0])\n",
        "\n",
        "# Visualizar la forma de onda\n",
        "plt.plot(time1, data1[:, 0], label=\"Left channel\")\n",
        "plt.plot(time1, data1[:, 1], label=\"Right channel\")\n",
        "plt.legend()\n",
        "plt.xlabel('Tiempo (muestras)')\n",
        "plt.ylabel('Amplitud')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7108aa8d",
      "metadata": {
        "id": "7108aa8d"
      },
      "source": [
        "## Separación por canales de una señal\n",
        "\n",
        "Si el archivo que se carga está en formato estéreo (dos canales), estos pueden ser separados para poder pintarlos en gráficos diferentes.\n",
        "\n",
        "En este caso, se lee la señal de la misma manera y se crean dos variables (llamadas en el ejemplo *left* y *right*), para tomar cada uno de los canales (0 y 1).\n",
        "\n",
        "Posteriormente se crean dos subplots que permitirán visualizar cada canal por aparte."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c40c4d02",
      "metadata": {
        "id": "c40c4d02"
      },
      "outputs": [],
      "source": [
        "# Reproducir los audios a cargar\n",
        "Audio(\"files/567781__rentless__hi-tones-random.wav\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b790d8ce",
      "metadata": {
        "id": "b790d8ce"
      },
      "outputs": [],
      "source": [
        "# Cargar el segundo archivo de audio\n",
        "samplerate2, data2 = wav.read(\"files/567781__rentless__hi-tones-random.wav\")\n",
        "print(samplerate2, \"Hz\") # Imprimir la frecuencia de muestreo de la primera señal\n",
        "\n",
        "# Separar los canales\n",
        "left2 = data2[:, 0]\n",
        "right2 = data2[:, 1]\n",
        "\n",
        "# Calcula la longitud (en tiempo) de la señal\n",
        "length2 = data2.shape[0] / samplerate2\n",
        "\n",
        "#La variable independiente time2 se tomará en el rango [0, length2] y se graficará según el número de muestras en el audio1.\n",
        "time2 = np.linspace(0., length2, data2.shape[0])\n",
        "\n",
        "# Crear dos subplots\n",
        "fig, (ax_left, ax_right) = plt.subplots(nrows=2, sharex=True, sharey=True)\n",
        "\n",
        "# Dibujar la señal del canal izquierdo en el primer subplot\n",
        "ax_left.plot(time2, left2)\n",
        "ax_left.set(title='Canal izquierdo')\n",
        "\n",
        "# Dibujar la señal del canal derecho en el segundo subplot\n",
        "ax_right.plot(time2, right2)\n",
        "ax_right.set(title='Canal derecho')\n",
        "\n",
        "# Mostrar los gráficos\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "697c1f40",
      "metadata": {
        "id": "697c1f40"
      },
      "source": [
        "## Operaciones sobre señales de audio\n",
        "\n",
        "Dado que se cuenta con dos señales de audio, es posible realizar las operaciones listadas previamente sobre estas señales como forma de aplicación.\n",
        "\n",
        "### Cambio en longitud (Zero padding)\n",
        "\n",
        "Dado que ambas señales no tienen la misma longitud, es necesario igualarlas para poder realizar algunas operaciones sobre ellas. Es así como la señal más pequeña se rellena de ceros, generando dos arreglos de igual longitud. Este cambio puede realizarse al principio o al final de la señal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d666187a",
      "metadata": {
        "id": "d666187a"
      },
      "outputs": [],
      "source": [
        "#Como el canal 1 no se había separado, se procede a hacerlo\n",
        "left1 = data1[:, 0]\n",
        "right1 = data1[:, 1]\n",
        "\n",
        "# Para visualizar las señales en una misma gráfica, es necesario que ambas señales tengan la misma longitud\n",
        "# Primero se obtiene la longitud máxima de las señales\n",
        "\n",
        "# Imprimir la longitud del audio 1 (en cantidad de muestras)\n",
        "print(len(left1), \"muestras\")\n",
        "\n",
        "# Imprimir la longitud del audio 2 (en cantidad de muestras)\n",
        "print(len(left2), \"muestras\")\n",
        "\n",
        "max_len = max(len(left1), len(left2))\n",
        "\n",
        "# Se define una función sencilla para realizar alineación con ceros de las dos señales\n",
        "def return_padded(max_l, signal):\n",
        "    return np.pad(signal, (0, max_l - len(signal)), mode='constant')\n",
        "\n",
        "# Se usa la función para que todas las señales tengan la misma longitud\n",
        "left1 = return_padded(max_len, left1)\n",
        "right1 = return_padded(max_len, right1)\n",
        "left2 = return_padded(max_len, left2)\n",
        "right2 = return_padded(max_len, right2)\n",
        "\n",
        "# Dado que ambas frecuencias de muestreo son iguales y la cantidad de datos fue igualada\n",
        "# Calcula la longitud (en tiempo) de la señal\n",
        "length = max_len / samplerate1\n",
        "print(length, \"segundos\")\n",
        "\n",
        "#La variable independiente time se tomará en el rango [0, length] y se graficará según el número de muestras en el audio1.\n",
        "time = np.linspace(0., length, max_len)\n",
        "\n",
        "# Visualizar la forma de onda\n",
        "plt.plot(time, left1, label=\"Left channel - Audio 1\")\n",
        "plt.plot(time, right1, label=\"Right channel - Audio 1\")\n",
        "plt.plot(time, left2, label=\"Left channel - Audio 2\")\n",
        "plt.plot(time, right2, label=\"Right channel - Audio 2\")\n",
        "plt.legend(loc='best')\n",
        "plt.xlabel('Tiempo (muestras)')\n",
        "plt.ylabel('Amplitud')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3dc88d87",
      "metadata": {
        "id": "3dc88d87"
      },
      "source": [
        "### Cambio en amplitud\n",
        "\n",
        "En la gráfica se puede ver que una de las señales tiene mayor amplitud que la otra, vamos a cambiar la amplitud de ambas señales y a graficarlas nuevamente. El proceso de cambio en amplitud consiste en multiplicar todos los componentes de la señal por un factor de escala."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42db45f1",
      "metadata": {
        "id": "42db45f1"
      },
      "outputs": [],
      "source": [
        "# Definir el factor de escalamiento en amplitud para disminuir el volumen de la señal\n",
        "factor1 = 0.1\n",
        "\n",
        "# Multiplicar la señal por dicho factor de escala:\n",
        "left1_scaled = left1 * factor1\n",
        "right1_scaled = right1 * factor1\n",
        "\n",
        "# Definir el factor de escalamiento en amplitud para aumentar el volumen de la señal\n",
        "factor2 = 2\n",
        "\n",
        "# Multiplicar la señal por dicho factor de escala:\n",
        "left2_scaled = left2 * factor2\n",
        "right2_scaled = right2 * factor2\n",
        "\n",
        "# Visualizar la forma de onda\n",
        "plt.plot(time, left1_scaled, label=\"Left channel - Audio 1\")\n",
        "plt.plot(time, right1_scaled, label=\"Right channel - Audio 1\")\n",
        "plt.plot(time, left2_scaled, label=\"Left channel - Audio 2\")\n",
        "plt.plot(time, right2_scaled, label=\"Right channel - Audio 2\")\n",
        "plt.legend()\n",
        "plt.xlabel('Tiempo (muestras)')\n",
        "plt.ylabel('Amplitud')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56b001ab",
      "metadata": {
        "scrolled": true,
        "id": "56b001ab"
      },
      "outputs": [],
      "source": [
        "# Se suman los datos de dos arreglos\n",
        "\n",
        "sum_left = left1_scaled + left2_scaled\n",
        "sum_right = right1_scaled + right2_scaled\n",
        "\n",
        "# Visualizar la forma de onda\n",
        "plt.plot(time, sum_left, label=\"Left channel\")\n",
        "plt.plot(time, sum_right, label=\"Right channel\")\n",
        "plt.legend()\n",
        "plt.xlabel('Tiempo (muestras)')\n",
        "plt.ylabel('Amplitud')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "778838b9",
      "metadata": {
        "scrolled": true,
        "id": "778838b9"
      },
      "outputs": [],
      "source": [
        "# Es necesario reconstruir la señal WAV convirtiendo los arreglos fila a columna\n",
        "sum_left_col = np.reshape(sum_left,(-1,1))\n",
        "sum_right_col = np.reshape(sum_right,(-1,1))\n",
        "\n",
        "# Posteriormente se concatenan en un arreglo de dos columnas (de la forma como venía originalmente el archivo)\n",
        "sum_audio = np.concatenate((sum_left_col, sum_right_col), axis=1)\n",
        "print(sum_audio.astype(np.int16))\n",
        "\n",
        "# Escribir la señal resultante en un archivo de audio\n",
        "wav.write('files/sum_output.wav', samplerate1, sum_audio.astype(np.int16))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c8f0d8c",
      "metadata": {
        "id": "3c8f0d8c"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Audio\n",
        "\n",
        "#Reproducir el resultado\n",
        "Audio(\"files/sum_output.wav\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a998d27d",
      "metadata": {
        "id": "a998d27d"
      },
      "source": [
        "## Inversión de la señal\n",
        "\n",
        "Se desea invertir el tiempo de la señal $x(t) = x(-t)$. En este caso se usa la función flip de NumPy, que retorna el arreglo invertido."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cdfcc888",
      "metadata": {
        "id": "cdfcc888"
      },
      "outputs": [],
      "source": [
        "sum_left_inv = np.flip(sum_left, axis=None)\n",
        "sum_right_inv = np.flip(sum_right, axis=None)\n",
        "\n",
        "# Visualizar la forma de onda\n",
        "plt.plot(time, sum_left_inv, label=\"Left channel\")\n",
        "plt.plot(time, sum_right_inv, label=\"Right channel\")\n",
        "plt.legend()\n",
        "plt.xlabel('Tiempo (muestras)')\n",
        "plt.ylabel('Amplitud')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66555a8b",
      "metadata": {
        "id": "66555a8b"
      },
      "outputs": [],
      "source": [
        "# Generar nuevamente la señal WAV\n",
        "sum_left_col = np.reshape(sum_left_inv,(-1,1))\n",
        "sum_right_col = np.reshape(sum_right_inv,(-1,1))\n",
        "sum_audio = np.concatenate((sum_left_col, sum_right_col), axis=1)\n",
        "print(sum_audio.astype(np.int16))\n",
        "\n",
        "# Escribir la señal resultante en un archivo de audio\n",
        "wav.write('files/sum_output_flipped.wav', samplerate1, sum_audio.astype(np.int16))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f5c719c",
      "metadata": {
        "id": "9f5c719c"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Audio\n",
        "\n",
        "#Reproducir el resultado\n",
        "Audio(\"files/sum_output_flipped.wav\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}